steps:
# 1. Fetch the source code
- name: gcr.io/cloud-builders/git
  args: ['clone', 'https://github.com/polleyg/gcp-batch-ingestion-bigquery.git']
  
# 2a. Set up GCS & BQ etc. using public terraform Docker image
- name: hashicorp/terraform
  args: ['init']
  dir: 'terraform'
 
# 2b. Create the GCS bucket using Terraform
- name: hashicorp/terraform
  id: terraform-apply
  args: ['apply', '-auto-approve']
  dir: 'terraform'

  
# 4. Deploy the Cloud Function
- name: 'gcr.io/cloud-builders/gcloud'
  args:
  - functions
  - deploy
  - hello_world_v
  - --source=.
  - --stage-bucket=gs://my_terra_test
  - --trigger-bucket=gs://my_terra_test
  - --runtime=python37
  - --allow-unauthenticated
  - --service-account=sandbox-257707@appspot.gserviceaccount.com 
  
# 5. Build and run the Dataflow pipeline (staged template)
- name: gcr.io/cloud-builders/gradle
  args: ['build', 'run']
  waitFor: ['terraform-apply']








